
-------------------------------------------
start.sh:

    determine number of processor cores
    run cleanup.sh
    run ref_gen.sh (line69<--doesn't check ref_gen.sh's exit code, even though exit 1 means we should abort)
    if single
        if unpaired (0), run args.sh for each datapoint filename in ./data
        if paired (1), run args.sh once for each unique string obtained by chopping the last 13 characters off the filenames (which includes _R1 or _R2) in ./data (therefore only run args.sh once per R1 & R2 pair).
    if pooled, run args.sh, passing in $name as the first parameter
    if both
        do pooled call of args.sh in background (line 91<-- should it run in background? maybe should run before or after the singles, each with the full number of processors)
        do single routine
    run gen_report.sh with $mafcut parameter


-------------------------------------------
ref_gen.sh:
parameters: $1 9number of cores)

    export PERL5LIB=$PERL5LIB:`pwd`/tools/vcftools/src/perl
    rm -f ./reference/*.fai
    for each file in ./reference 
        increment c
        set ref to filename
    if c > 1
        found multiple references, concat all files in /reference to one file called output.fasta, delete all other files
        set ref to output.fasta
    if c == 0
        found no reference, exit 1 
    if ref != formatted_output.fasta
        echo "formatting fasta file to consistent line lengths"
        java -jar ./tools/picard-tools-2.3.0/picard.jar NormalizeFasta I=./reference/$ref O=./reference/"formatted_output.fasta" LINE_LENGTH=60 
    delete original fasta file
    echo "build new ref"
    run bowtie2-build --threads $ncore $newref $ref 
    echo "build fai for reference"
    run samtools faidx "./reference/formatted_output.fasta"

-------------------------------------------
args.sh:
parameters: $1 ($datapoint for single, $name for pooled), $2 (name), $3 (1=single/2=pooled/3=both), $4 (singlep/combinedp), $5 (number of cores), $6 (params: 1=default, 0=paper, 3=custom), $7 (1=assemble, 0= non-assemble)

    set permissions on all files in ./data to read and execute, not write
    if single, run align.sh $1 $5 $7
    if pooled, run align_all.sh $1 $5 $7
    if single, run extract.sh $1 $4 $3 $6
    if pooled, run extract.sh $1 $4 $3 $6 (with different log file)
    if single, run post_process.sh $1 $3
    if pooled, run post_process.sh $1 $3 (with different log file)
    (<-- the $2 parameter is never used)

-------------------------------------------
align.sh:
parameters: $1 (name/datapoint), $2 (number of cores), $3 (1=assemble, 0=non-assemble)

    input=$1
    ref="./referenceTemp/formatted_output"
    if unpaired (0)
        run bowtie2 -p $2 -x $ref -U "./data/"$input --local --very-sensitive-local -S "./dataTemp/single/$input.sam"
    elif paired (1)
        run bowtie2 -p $2 -x $ref -1 "./data/$(ls "./data" | grep $input | sed -n 1p)" -2 "./data/$(ls "./data" | grep $input | sed -n 2p)" --local --very-sensitive-local -S "./dataTemp/single/$input.sam"

######
bowtie2 parameters:
-p: number of threads
-x: Index filename prefix (minus trailing .X.bt2).
-1: Files with #1 mates, paired with files in <m2>.
-2: Files with #2 mates, paired with files in <m1>.
-U: Files with unpaired reads.
-S: File for SAM output (default: stdout)
--local: local alignment; ends might be soft clipped (off)
--very-sensitive-local: -D 20 -R 3 -N 0 -L 20 -i S,1,0.50

-------------------------------------------
align_all.sh:
parameters: $1 (name/datapoint), $2 (number of cores), $3 (1=assemble, 0=non-assemble)

    input=$1
    ref="./referenceTemp/formatted_output"
    if unpaired (0)
        make a comma separated list of file names in .data
        run bowtie2 -p $2 -x $ref -U $data --local --very-sensitive-local -S "./dataTemp/pooled/$input.sam"
    if paired (1)
        make a comma separated list of R1 file names in .data
        make a comma separated list of R2 file names in .data
        run bowtie2 -p $2 -x $ref -1 $dataone -2 $datatwo --local --very-sensitive-local -S "./dataTemp/pooled/$input.sam"

-------------------------------------------
extract.sh:
parameters: $1 (name/datapoint), $2 (singlep/combinedp), $3 (1=single/2=pooled/3=both), $4 (params: 1=default, 0=paper, 3=custom)

    path="single" or "pooled"
    input="./dataTemp/$path/$1.sam"
    run samtools view -Sb $input > ./dataTemp/$path/$1.bam # this generates bam
    rm -f $input
    run samtools sort -o ./dataTemp/$path/$1_sorted.bam ./dataTemp/$path/$1.bam # this sorts bam (line 21,25,27<-- where does the $1_sorted variable come from? Should it be $1"_sorted"? - I think it's because $1, $2, etc are recognized as special positional parameters in bash)
    rm -f ./dataTemp/$path/$1.bam
    run samtools index ./dataTemp/$path/$1_sorted.bam 
    binput="./dataTemp/$path/$1_sorted.bam" 
    ref="./reference/formatted_output.fasta"
    if params==paper(0)
        run freebayes -f $ref -p $2 --pvar 0.75 --min-alternate-count 1 --theta 0.01  --use-best-n-alleles 4 --min-alternate-fraction 0.8 $binput 1> ./outputTemp/$path/$1.vcf
    elif params=default(1)
        run freebayes -f $ref -p $2 $binput 1> ./outputTemp/$path/$1.vcf

######
samtools parameters:
view: SAM<->BAM<->CRAM conversion
-S: ignored (input format is auto-detected)
-b: output BAM
sort: sort alignment file
-o FILE    Write final output to FILE rather than standard output
index: index alignment
faidx: index/extract FASTA

######
freebayes parameters, paper:
- fasta reference file
- default ploidy = $singlep/$combinedp (default 2)
- --pvar (report sites if probability of polymorphism is greater than): 0.75 (default 0.0) (Note that post-filtering is generally recommended over the use of this parameter).
- --min-alternate-count (min # of observations supporting an alternate allele within a single individual in order to evaluate this position): 1 (default 0.2)
- --theta (expected mutation rate or pairwise nucleotide diversity): 0.01 (default 0.001)
- --use-best-n-alleles: 4 (Set to 0 to use all; default: all)
- --min-alternate-fraction: 0.8 (default 0.2)
- bam input file
######
freebayes parameters, default:
- fasta reference file
- default ploidy = $singlep/$combinedp (default 2)
- --pvar (report sites if probability of polymorphism is greater than): (default 0.0) (Note that post-filtering is generally recommended over the use of this parameter).
- --min-alternate-count (min # of observations supporting an alternate allele within a single individual in order to evaluate this position): (default 0.2)
- --theta (expected mutation rate or pairwise nucleotide diversity): (default 0.001)
- --use-best-n-alleles: (Set to 0 to use all; default: all)
- --min-alternate-fraction: (default 0.2)
- bam input file

-------------------------------------------
post_process.sh:
parameters: $1 (name/datapoint), $2 (1=single/2=pooled/3=both)

    export PERL5LIB=`pwd`"/tools/vcftools/src/perl"
    echo "removing indels"
    if single
        run vcftools --vcf ./outputTemp/single/$1.vcf --remove-indels --recode --recode-INFO-all --out ./outputTemp/single/$1
    if pooled
        run vcftools --vcf ./outputTemp/pooled/$1.vcf --remove-indels --recode --recode-INFO-all --out ./outputTemp/pooled/$1
    echo "filtering using cutoffs"
    if single
        run cat ./outputTemp/single/$1.recode.vcf | ./tools/vcftools/src/perl/vcf-annotate --filter Qual=5 > ./outputTemp/single/$1_cutoff
    if pooled
        run cat ./outputTemp/pooled/$1.recode.vcf | ./tools/vcftools/src/perl/vcf-annotate --filter Qual=5 > ./outputTemp/pooled/$1_cutoff
    echo "tab conversion"
    if single
        run vcf-to-tab < ./outputTemp/single/$1_cutoff > ./output/single/$1.tab
    if pooled
        run vcf-to-tab < ./outputTemp/pooled/$1_cutoff > ./output/pooled/$1.tab 

-------------------------------------------
gen_report.sh:
parameters: $1 (mafcut)

    Rscript ./scripts/report_gen.R `pwd`
    Rscript ./scripts/report_subset.R `pwd`
    calculate number of processors (line 5<--This is doing *2 to the number of processors, is this a bug?)
    for each file in ./reporttemp not containing "filled.Rds" in the name
        if counter < number of cores
            Rscript ./scripts/parallel_process.R `pwd` $f & 
            increment counter
        else
            wait for all currently active child processes to finish 
    wait for all currently active child processes to finish
    Rscript ./scripts/report_gen_p2.R `pwd` $1

-------------------------------------------

-------------------------------------------

-------------------------------------------

-------------------------------------------

-------------------------------------------

-------------------------------------------
